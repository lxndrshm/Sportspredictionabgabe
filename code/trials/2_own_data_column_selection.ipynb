{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the needed packages\n",
    "%pip install pathlib pandas numpy tensorflow tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import os\n",
    "import signal\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters.\n",
    "LOGS_PATH = '../logs'\n",
    "DATA_PATH = '../data/own_data_preparation.csv'\n",
    "RESULT_COLUMN = 'result_team1'\n",
    "DUMMY_COLUMNS = ['team1', 'team2']\n",
    "NORMAILZE_COLUMNS = ['points', 'squard',\n",
    "    'average_age', 'average_market_value_in_euro', 'total_market_value_in_euro',\n",
    "    'rank_last_season', 'points_last_season_all', 'points_last_season']\n",
    "VALIDATION_SIZE = 0.2\n",
    "LOSS_FUNCTION = 'sparse_categorical_crossentropy'\n",
    "OPTIMIZER_FUNCTION = 'Adam'\n",
    "METRICS = 'sparse_categorical_accuracy'\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "TITLE = 'column_selection'\n",
    "MIN_COLUMNS = 1\n",
    "\n",
    "TENSORBOARD_PROCESS = 'tensorboard'\n",
    "TENSORBOARD_SERVER = 'localhost'\n",
    "TENSORBOARD_PORT = 6008\n",
    "\n",
    "LOGS_PATH = os.path.join(LOGS_PATH, TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tensorboard.\n",
    "%load_ext tensorboard\n",
    "logs = Path(LOGS_PATH)\n",
    "logs.mkdir(mode=0o777, parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set.\n",
    "data = pd.read_csv(DATA_PATH, delimiter=',', decimal='.')\n",
    "\n",
    "# Create the difference between team1 and team2 for each feature.\n",
    "for column in NORMAILZE_COLUMNS:\n",
    "    data[column] = data[column + '_team1'] - data[column + '_team2']\n",
    "\n",
    "# Normalize column using the max value for each column.\n",
    "for column in NORMAILZE_COLUMNS:\n",
    "    max_value = data[column].max()\n",
    "    data[column] = data[column].apply(lambda x: x / max_value)\n",
    "\n",
    "# Get the wanted columns and create dummy columns for the teams.\n",
    "data = data.loc[:, DUMMY_COLUMNS + NORMAILZE_COLUMNS + [RESULT_COLUMN]]\n",
    "data = pd.get_dummies(data, columns=DUMMY_COLUMNS)\n",
    "\n",
    "# Drop rows with nan values.\n",
    "data = data.dropna()\n",
    "\n",
    "# Split the data set.\n",
    "split_index = int(len(data) * VALIDATION_SIZE)\n",
    "data = data.sample(frac=1)\n",
    "data_train = data[split_index:]\n",
    "data_valid = data[:split_index]\n",
    "\n",
    "par_train = data_train.loc[:, data_train.columns != RESULT_COLUMN]\n",
    "res_train = data_train.loc[:, [RESULT_COLUMN]]\n",
    "par_valid = data_valid.loc[:, data_train.columns != RESULT_COLUMN]\n",
    "res_valid = data_valid.loc[:, [RESULT_COLUMN]]\n",
    "\n",
    "dummies = [key for key in par_train.keys() if 'team' in key]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frames to numpy arrays.\n",
    "res_train = res_train.to_numpy()\n",
    "res_valid = res_valid.to_numpy()\n",
    "\n",
    "print(par_train.shape)\n",
    "print(res_train.shape)\n",
    "print(par_valid.shape)\n",
    "print(res_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineModel(input_dim):\n",
    "    # Define the model\n",
    "    nodes = input_dim*2-1\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(nodes, activation='tanh', input_dim=input_dim),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(loss=LOSS_FUNCTION, optimizer=OPTIMIZER_FUNCTION, metrics=[METRICS])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(model, x_train, x_valid, y_train, y_valid, title):\n",
    "    # Define callback function for writing data for tensorBoard\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.path.join(LOGS_PATH, title), histogram_freq=1)\n",
    "\n",
    "    # Run the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        callbacks=[tensorboard_callback],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run combinations of two columns without teams.\n",
    "list_combinations = []\n",
    "for i in range(MIN_COLUMNS, len(NORMAILZE_COLUMNS)):\n",
    "    list_combinations += combinations(NORMAILZE_COLUMNS, i)\n",
    "\n",
    "for columns in list_combinations:\n",
    "    columns = list(columns)\n",
    "    sel_train = par_train.loc[:, columns]\n",
    "    sel_valid = par_valid.loc[:, columns]\n",
    "\n",
    "    sel_train = sel_train.to_numpy()\n",
    "    sel_valid = sel_valid.to_numpy()\n",
    "\n",
    "    name = str(len(columns))+'_'+'--'.join(columns)+'_without_teams'\n",
    "    runModel(defineModel(sel_train.shape[1]), sel_train, sel_valid, res_train, res_valid, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run combinations of columns with teams.\n",
    "list_combinations = []\n",
    "for i in range(MIN_COLUMNS, len(NORMAILZE_COLUMNS)):\n",
    "    list_combinations += combinations(NORMAILZE_COLUMNS, i)\n",
    "\n",
    "for columns in list_combinations:\n",
    "    columns = list(columns)\n",
    "    sel_train = par_train.loc[:, dummies + columns]\n",
    "    sel_valid = par_valid.loc[:, dummies + columns]\n",
    "\n",
    "    sel_train = sel_train.to_numpy()\n",
    "    sel_valid = sel_valid.to_numpy()\n",
    "\n",
    "    name = str(len(columns))+'_'+'--'.join(columns)+'_with_teams'\n",
    "    runModel(defineModel(sel_train.shape[1]), sel_train, sel_valid, res_train, res_valid, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only team columns.\n",
    "sel_train = par_train.loc[:, dummies]\n",
    "sel_valid = par_valid.loc[:, dummies]\n",
    "\n",
    "sel_train = sel_train.to_numpy()\n",
    "sel_valid = sel_valid.to_numpy()\n",
    "\n",
    "runModel(defineModel(sel_train.shape[1]), sel_train, sel_valid, res_train, res_valid, '0_only_teams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only not team columns.\n",
    "sel_train = par_train.loc[:, NORMAILZE_COLUMNS]\n",
    "sel_valid = par_valid.loc[:, NORMAILZE_COLUMNS]\n",
    "\n",
    "sel_train = sel_train.to_numpy()\n",
    "sel_valid = sel_valid.to_numpy()\n",
    "\n",
    "runModel(defineModel(sel_train.shape[1]), sel_train, sel_valid, res_train, res_valid, '0_only_not_teams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns.\n",
    "sel_train = par_train.to_numpy()\n",
    "sel_valid = par_valid.to_numpy()\n",
    "\n",
    "runModel(defineModel(sel_train.shape[1]), sel_train, sel_valid, res_train, res_valid, '0_all_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill the existing tensorboard process and delete the tensorflow temp folder. After this start a new tensorboard process.\n",
    "try:    \n",
    "    # Iterating through each instance of the process.\n",
    "    for line in os.popen(\"ps ax | grep \" + TENSORBOARD_PROCESS + \" | grep -v grep\"):\n",
    "        fields = line.split()\n",
    "            \n",
    "        # Extracting Process ID from the output.\n",
    "        pid = fields[0]\n",
    "            \n",
    "        # Terminating process.\n",
    "        os.kill(int(pid), signal.SIGKILL)\n",
    "\n",
    "    # Delete tensorboard temp folder.\n",
    "    tb_temp_folder = os.path.join(tempfile.gettempdir(), '.tensorboard-info')\n",
    "    os.system(\"rm -rf \"+tb_temp_folder)\n",
    "    print(\"Process Successfully terminated\") \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "%tensorboard --logdir $LOGS_PATH --host $TENSORBOARD_SERVER --port $TENSORBOARD_PORT"
   ]
  }
 ],
 "metadata": {
  "accelerator": "CPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tensorboard_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
