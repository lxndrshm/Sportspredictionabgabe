{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the needed packages\n",
    "%pip install pathlib pandas numpy tensorflow tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import os\n",
    "import signal\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters.\n",
    "LOGS_PATH = '../logs'\n",
    "DATA_PATH = '../data/own_data_preparation.csv'\n",
    "RESULT_COLUMN = 'result_team1'\n",
    "RESULT_HEADERS = ['loss_team1', 'draw', 'win_team1']\n",
    "RESULT_INFO_COLUMNS = ['season', 'date', 'team1', 'team2']\n",
    "DUMMY_COLUMNS = ['team1', 'team2']\n",
    "NORMAILZE_COLUMNS = ['points', 'squard',\n",
    "    'average_age', 'average_market_value_in_euro', 'total_market_value_in_euro',\n",
    "    'rank_last_season', 'points_last_season_all', 'points_last_season']\n",
    "WITH_TEAMS = False\n",
    "VALIDATION_SIZE = 0.2\n",
    "LOSS_FUNCTION = 'sparse_categorical_crossentropy'\n",
    "OPTIMIZER_FUNCTION = 'Adam'\n",
    "METRICS = 'sparse_categorical_accuracy'\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 32\n",
    "TITLE = 'prediction'\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "TENSORBOARD_PROCESS = 'tensorboard'\n",
    "TENSORBOARD_SERVER = 'localhost'\n",
    "TENSORBOARD_PORT = 6008\n",
    "\n",
    "LOGS_PATH = os.path.join(LOGS_PATH, TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tensorboard.\n",
    "%load_ext tensorboard\n",
    "logs = Path(LOGS_PATH)\n",
    "logs.mkdir(mode=0o777, parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "data = pd.read_csv(DATA_PATH, delimiter=',', decimal='.')\n",
    "\n",
    "# Create the difference between team1 and team2 for each feature.\n",
    "for column in NORMAILZE_COLUMNS:\n",
    "    data[column] = data[column + '_team1'] - data[column + '_team2']\n",
    "\n",
    "# Normalize column using the max value for each column.\n",
    "for column in NORMAILZE_COLUMNS:\n",
    "    max_value = data[column].max()\n",
    "    data[column] = data[column].apply(lambda x: x / max_value)\n",
    "\n",
    "# Get columns for result table.\n",
    "result_info = data[data[RESULT_COLUMN].isna()]\n",
    "result_info = result_info.loc[:, RESULT_INFO_COLUMNS]\n",
    "\n",
    "# Get the wanted columns and create dummy columns for the teams.\n",
    "if WITH_TEAMS:\n",
    "    data_cal = data.loc[:, DUMMY_COLUMNS + NORMAILZE_COLUMNS + [RESULT_COLUMN]]\n",
    "    data_cal = pd.get_dummies(data_cal, columns=DUMMY_COLUMNS)\n",
    "else:\n",
    "    data_cal = data.loc[:, NORMAILZE_COLUMNS + [RESULT_COLUMN]]\n",
    "\n",
    "# Separate columns with match results from the ones that have none.\n",
    "data_prediction = data_cal[data_cal[RESULT_COLUMN].isna()]\n",
    "data_modeling = data_cal.dropna()\n",
    "\n",
    "# Split the data set.\n",
    "split_index = int(len(data_modeling) * VALIDATION_SIZE)\n",
    "data_modeling = data_modeling.sample(frac=1)\n",
    "data_train = data_modeling[split_index:]\n",
    "data_valid = data_modeling[:split_index]\n",
    "\n",
    "par_train = data_train.loc[:, data_train.columns != RESULT_COLUMN]\n",
    "res_train = data_train.loc[:, [RESULT_COLUMN]]\n",
    "par_valid = data_valid.loc[:, data_train.columns != RESULT_COLUMN]\n",
    "res_valid = data_valid.loc[:, [RESULT_COLUMN]]\n",
    "data_prediction = data_prediction.loc[:, data_train.columns != RESULT_COLUMN]\n",
    "\n",
    "if WITH_TEAMS:\n",
    "    dummies = [key for key in par_train.keys() if 'team' in key]\n",
    "\n",
    "data_modeling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frames to numpy arrays.\n",
    "res_train = res_train.to_numpy()\n",
    "res_valid = res_valid.to_numpy()\n",
    "\n",
    "print(par_train.shape)\n",
    "print(res_train.shape)\n",
    "print(par_valid.shape)\n",
    "print(res_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineModel(input_dim):\n",
    "    # Define the model\n",
    "    nodes = input_dim*2-1\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(nodes, activation='relu', input_dim=input_dim),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Define the optimizer function.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(loss=LOSS_FUNCTION, optimizer=optimizer, metrics=[METRICS])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(model, x_train, x_valid, y_train, y_valid, title):\n",
    "    # Define callback function for writing data for tensorBoard\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.path.join(LOGS_PATH, title), histogram_freq=1)\n",
    "\n",
    "    # Run the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        callbacks=[tensorboard_callback],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model.\n",
    "sel_train = par_train.to_numpy()\n",
    "sel_valid = par_valid.to_numpy()\n",
    "\n",
    "model = defineModel(sel_train.shape[1])\n",
    "history = runModel(model, sel_train, sel_valid, res_train, res_valid, TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if the order of the prediction data set is not changed by tensorflow => Otherwise the code below would merge the wrong infos to the predictions.\n",
    "# TODO: Check if the order of predictions results is correct (loss, draw, win) => Otherwise the table headers, need to be changed.\n",
    "\n",
    "# Make predictions.\n",
    "result_info = result_info.to_numpy()\n",
    "pre_data = data_prediction.to_numpy()\n",
    "\n",
    "predictions = model.predict(pre_data)\n",
    "\n",
    "# Show the predictions as table.\n",
    "result = []\n",
    "for i in range(0, len(predictions)):\n",
    "    item = list(result_info[i]) + list(predictions[i])\n",
    "    result.append(item)\n",
    "\n",
    "result = pd.DataFrame(result, columns = RESULT_INFO_COLUMNS + RESULT_HEADERS)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill the existing tensorboard process and delete the tensorflow temp folder. After this start a new tensorboard process.\n",
    "try:    \n",
    "    # Iterating through each instance of the process.\n",
    "    for line in os.popen(\"ps ax | grep \" + TENSORBOARD_PROCESS + \" | grep -v grep\"):\n",
    "        fields = line.split()\n",
    "            \n",
    "        # Extracting Process ID from the output.\n",
    "        pid = fields[0]\n",
    "            \n",
    "        # Terminating process.\n",
    "        os.kill(int(pid), signal.SIGKILL)\n",
    "\n",
    "    # Delete tensorboard temp folder.\n",
    "    tb_temp_folder = os.path.join(tempfile.gettempdir(), '.tensorboard-info')\n",
    "    os.system(\"rm -rf \"+tb_temp_folder)\n",
    "    print(\"Process Successfully terminated\") \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "%tensorboard --logdir $LOGS_PATH --host $TENSORBOARD_SERVER --port $TENSORBOARD_PORT"
   ]
  }
 ],
 "metadata": {
  "accelerator": "CPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tensorboard_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
